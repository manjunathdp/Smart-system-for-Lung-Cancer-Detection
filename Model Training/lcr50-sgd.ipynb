{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5067999,"sourceType":"datasetVersion","datasetId":2942631},{"sourceId":5075335,"sourceType":"datasetVersion","datasetId":2946961}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm\nfrom numpy import asarray\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n#from keras.applications.resnet import ResNet50\n#from keras.applications.resnet import ResNet50\nfrom tensorflow.keras.applications.resnet import decode_predictions\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.layers import Input,UpSampling2D,Flatten,BatchNormalization,Dense,Dropout,GlobalAveragePooling2D\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom glob import glob\nfrom PIL import Image\nimport pandas as pd\nimport os\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2023-03-28T22:07:07.613412Z","iopub.execute_input":"2023-03-28T22:07:07.614266Z","iopub.status.idle":"2023-03-28T22:07:15.569770Z","shell.execute_reply.started":"2023-03-28T22:07:07.614221Z","shell.execute_reply":"2023-03-28T22:07:15.568695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Implimenting ResNET50 ARCH**","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = [512, 512]\n\ntrain_path = '/kaggle/input/lung-cancer-dataset/Lung cancer dataset/train'\nval_path = '/kaggle/input/lung-cancer-dataset/Lung cancer dataset/val'\n\nfolders = glob(train_path+'/*')\nprint(\"Number of classes:\",len(folders))\nnum_classes = len(folders)\nnb_epochs = 50\n\nresnet=ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# Fixed for our dataset\nNUM_CLASSES = num_classes\n\n# Fixed for Cats & Dogs color images\nCHANNELS = 3\n\nIMAGE_RESIZE = 512\nRESNET50_POOLING_AVERAGE = 'avg'\nDENSE_LAYER_ACTIVATION = 'softmax'\nOBJECTIVE_FUNCTION = 'categorical_crossentropy'\n\n# Common accuracy metric for all outputs, but can use different metrics for different output\nLOSS_METRICS = ['accuracy']\n\n# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n#NUM_EPOCHS = 60\n#EARLY_STOP_PATIENCE = 3\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\nSTEPS_PER_EPOCH_TRAINING = 10\nSTEPS_PER_EPOCH_VALIDATION = 2\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\nBATCH_SIZE_TRAINING =128\nBATCH_SIZE_VALIDATION =64\n\nfrom tensorflow.keras.models import Model,Sequential\nmodel4 = Sequential()\n\n# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\nmodel4.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = 'imagenet'))\n\n# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\nmodel4.add(Dense(num_classes, activation = 'softmax'))\n\n# Say not to train first layer (ResNet) model as it is already trained\nmodel4.layers[0].trainable = False\n\nmodel4.summary()\n\nfrom tensorflow.keras import optimizers\n\nsgd = optimizers.SGD(learning_rate = 0.001, momentum = 0.9, nesterov = True)\nmodel4.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)\n\n\n\n\n\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = IMAGE_RESIZE\n\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = data_generator.flow_from_directory(\n        train_path,\n        target_size=(image_size, image_size),\n        batch_size=BATCH_SIZE_TRAINING,\n        class_mode='categorical')\n\n\nvalidation_generator = data_generator.flow_from_directory(\n        val_path,\n        target_size=(image_size, image_size),\n        batch_size=BATCH_SIZE_VALIDATION,\n        class_mode='categorical')\n# Define the callback\ncheckpoint = ModelCheckpoint('best_weights_val_accuracy.h5', \n                              monitor='val_accuracy', \n                              save_best_only=True, \n                              save_weights_only=False,\n                              mode='max', \n                              verbose=1)\n\nhistory = model4.fit(\n        train_generator,\n        epochs = nb_epochs,\n        validation_data=validation_generator,\n        callbacks=[checkpoint]#,\n    #steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n    #validation_steps=STEPS_PER_EPOCH_VALIDATION\n        \n        )\n\nmodel4.save(\"SGD_lr0.001_ep50_resnet50.h5\")\nprint(\"Saved model to disk\")\n\ndf = pd.DataFrame(history.history)\ndf.to_csv('SGD_lr0.0001_trial_1.2_Resnet50history.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T22:07:19.826379Z","iopub.execute_input":"2023-03-28T22:07:19.827057Z","iopub.status.idle":"2023-03-28T22:29:34.041838Z","shell.execute_reply.started":"2023-03-28T22:07:19.827021Z","shell.execute_reply":"2023-03-28T22:29:34.040490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predication**","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import load_model\n\n# Load the model from the H5 file\nmodel = load_model('/kaggle/working/SGD_lr0.001_ep50_resnet50.h5')\n\nDIRECTORY= \"/kaggle/input/lung-cancer-dataset/Lung cancer dataset/test\"\nclass_names=['Bengin case','Malignant case','Normal case']\n\ndata = {'class': [],\n        'predicate_class': [],\n        'status': []}\npcount=0\nfcount=0\ntotalb=totalm=totaln=fb=fm=fn=0.0\ndf = pd.DataFrame(data)\nfor img in os.listdir(DIRECTORY):\n    img_path=os.path.join(DIRECTORY,img)\n    img_array=cv2.imread(img_path)\n    img_array=cv2.resize(img_array,(512,512))\n    img_array_=img_array\n    img_array_=np.expand_dims(img_array_,axis=0)\n    pred=model.predict(np.array(img_array_))\n    output_class=class_names[np.argmax(pred)]\n    s=img.split()\n    ctemp=s[0]+\" \"+s[1]\n    if(ctemp=='Bengin case'):\n        totalb=totalb+1\n    if(ctemp=='Malignant case'):\n        totalm=totalm+1\n    if(ctemp=='Normal case'):\n        totaln=totaln+1\n    if(ctemp==output_class):\n        temp = {'class': ctemp, 'predicate_class': output_class , 'status':'pass'}\n        pcount=pcount+1\n        df = df.append(temp, ignore_index=True)\n    else :\n        temp = {'class': ctemp, 'predicate_class': output_class , 'status':'fail'}\n        fcount=fcount+1\n        df = df.append(temp, ignore_index=True)\n\n        if(ctemp=='Bengin case'):\n            fb=fb+1\n        if(ctemp=='Malignant case'):\n            fm=fm+1\n        if(ctemp=='Normal case'):\n            fn=fn+1\nprint(\"Predication Accuracy of each class\")\nprint('Bengin case',(((totalb-fb)/totalb)*100))\nprint('Malignant case',(((totalm-fm)/totalm)*100))\nprint('Normal case',(((totaln-fn)/totaln)*100))\nprint(\"Predication Accuracy of the model is \",((((totalb-fb)/totalb)*100)+(((totalm-fm)/totalm)*100)+(((totaln-fn)/totaln)*100))/3)\nprint(\"Pass count=\",pcount)\nprint(\"Fail count=\",fcount)\ndf\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T22:30:53.657923Z","iopub.execute_input":"2023-03-28T22:30:53.658356Z","iopub.status.idle":"2023-03-28T22:30:57.592440Z","shell.execute_reply.started":"2023-03-28T22:30:53.658318Z","shell.execute_reply":"2023-03-28T22:30:57.591385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('1.2.SGDdata_lr0.0001.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T15:54:18.207839Z","iopub.execute_input":"2023-02-27T15:54:18.208772Z","iopub.status.idle":"2023-02-27T15:54:18.215936Z","shell.execute_reply.started":"2023-02-27T15:54:18.208719Z","shell.execute_reply":"2023-02-27T15:54:18.214823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}